{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Web Search - Google\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we show you how to:\n",
    "- Define a tool that the LLM can reliably call using JSON output\n",
    "- Use the googlesearch module to search the internet if the LLM cannot answer a research question itself\n",
    "- Scrape and process the HTML pages into context for the LLM\n",
    "- Create a Bedrock Guardrail \n",
    "- Use the Guardrail in your calls to the Bedrock API\n",
    "\n",
    "We will use Bedrock's Claude Sonnet base model using the Boto3 API. \n",
    "\n",
    "**Note:** *This notebook can be used in SageMaker Studio or run locally if you setup your AWS credentials.*\n",
    "\n",
    "#### Prerequisites\n",
    "- This notebook requires permissions to access Amazon Bedrock\n",
    "- Ensure you have gone to the Bedrock models access page and enabled acceess to Anthropic Claude 3.5 Sonnet and Claude 3 Haiku \n",
    "\n",
    "If you are running this notebook without an Admin role, make sure that your notebook's role includes the following managed policies:\n",
    "- AmazonBedrockFullAccess\n",
    "\n",
    "#### Use case\n",
    "You are building a research assistant GenAI application. In some cases the user's question may be about an event, product, or service that is more recent than the cutoff training date for the LLM model or not within the model's knowledge. For these cases, we want the LLM model to call the internet search tool to gather context relating to the question. Then we can supply that context back to the LLM to answer the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notebook setup\n",
    "Before starting, let's install and import the required python packages. Then configure the region and modelId variables we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -qU pip\n",
    "!pip3 install -r requirements.txt\n",
    "!pip3 install -qU boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import string\n",
    "import pprint\n",
    "#from datetime import date\n",
    "#from datetime import datetime\n",
    "from googlesearch import search\n",
    "from bs4 import BeautifulSoup\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "\n",
    "#modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "#modelId = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "print(f\"Using modelId: {modelId}\")\n",
    "print(f\"Using region: {region}\")\n",
    "print('Running boto3 version:', boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a boto3 runtime client for calling the LLM and create a boto3 admin client for creating our Guardrail\n",
    "bedrock_runtime_client = boto3.client(service_name = 'bedrock-runtime', region_name = region,)\n",
    "bedrock_admin_client = boto3.client('bedrock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Searching and scraping\n",
    "\n",
    "In this example we create three function:\n",
    "* handle_search\n",
    "    * This function first calls Google search to get a list of URLs related to the user's question\n",
    "    * Then it iterates through the list of URLs to compile aggregated text that can be supplied to the LLM as context in the prompt\n",
    "* google_search\n",
    "    * This function uses the googlesearch module to obtain URL's related to the user's question\n",
    "    * Use the num_results parameter to control how many URLs you want returned\n",
    "* get_page_content\n",
    "    * This function uses the BeautifulSoup module to parse the html content of each URL\n",
    "    * Then the text is processed to remove spaces, blank lines, and short lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_page_content(url):\n",
    "    try:\n",
    "        # Use the requests module to get the contents of the URL\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}\n",
    "        # Check for link to PDF docs\n",
    "        if \".pdf\" in url.split('/')[-1]:\n",
    "            print(f\"Found a PDF file: {url} skipping...\")\n",
    "            return \"skip page\"\n",
    "        else:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            #print(f\"response right after requests get is: \\n{response}\")\n",
    "            if response:\n",
    "                # Parse HTML content\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                # Remove script and style elements\n",
    "                for script_or_style in soup([\"script\", \"style\"]):\n",
    "                    script_or_style.decompose()\n",
    "                # Get the text\n",
    "                text = soup.get_text()\n",
    "                # Break into lines and remove leading and trailing space on each\n",
    "                lines = (line.strip() for line in text.splitlines())\n",
    "                # Break multi-headlines into a line each\n",
    "                chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "                # Drop blank lines\n",
    "                no_blank_lines = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "                # Break into lines again and remove any short lines\n",
    "                lines = no_blank_lines.splitlines()\n",
    "                cleaned_text = \"\"\n",
    "                character_count = 0\n",
    "                for line in lines:\n",
    "                    if len(line) >= 20:\n",
    "                        cleaned_text += line\n",
    "                return cleaned_text\n",
    "            else:\n",
    "                raise Exception(\"No response from the web server.\")\n",
    "    except requests.exceptions.Timeout as timeout_err: \n",
    "        print(f\"Timeout on this URL: {url} skipping...\")\n",
    "        return \"skip page\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error while requesting content from {url} skipping...: {e}\")\n",
    "        return \"skip page\"\n",
    "\n",
    "def search_google(query):\n",
    "    try:\n",
    "        search_results = []\n",
    "        # Use the googlesearch module to get URLs related to the user's question\n",
    "        for url in search(query, sleep_interval=5, num_results=3):\n",
    "            search_results.append(url)\n",
    "        return search_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Google search: {e}\")\n",
    "        return []\n",
    "\n",
    "def handle_search(query):\n",
    "    # Proceed with Google search\n",
    "    print(\"Searching Google...\\n\")\n",
    "    urls_to_scrape = ['dummy']\n",
    "    # Sometimes Google will only return one url even if asked for more, try again if only one\n",
    "    while len(urls_to_scrape) == 1:\n",
    "        urls_to_scrape = search_google(query)\n",
    "        if len(urls_to_scrape) != 1:\n",
    "            break\n",
    "    aggregated_content = \"\"\n",
    "    for url in urls_to_scrape:\n",
    "        print(f\"Scraping URL: {url}\")\n",
    "        content = get_page_content(url)\n",
    "        #print(f\"\\nCONTENT for this url: {url} is: \\n{content}\")\n",
    "        if content and content != \"skip page\":\n",
    "            aggregated_content += content\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return aggregated_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tool definition\n",
    "\n",
    "provider_websearch_schema = {\n",
    "      \"toolSpec\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"A tool to retrieve up to date information from a Google search.\",\n",
    "        \"inputSchema\": {\n",
    "          \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The users question as-is to be searched by Google\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\"question\"]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "# In this example, we save only one tool schema to the configuration, but you could have many tools\n",
    "toolConfig = {\n",
    "    \"tools\": [provider_websearch_schema]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The function that answers the user's question based on aggregated Google search content\n",
    "def answer_question_with_content(question, content):\n",
    "    query = f\"\"\"\n",
    "    Based solely on this content:\n",
    "    <content>\n",
    "    {content}\n",
    "    </content>\n",
    "    Answer this question:\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "    Skip any preamble or references to the tool.\n",
    "    \"\"\"\n",
    "\n",
    "    converse_api_params = {\n",
    "        \"modelId\": modelId,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": query}]}],\n",
    "        \"system\": [{ \"text\": \"You are an expert research assistant.\" }],\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": 4096,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = bedrock_runtime_client.converse(**converse_api_params)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function that answers the user's question directly or outputs tool use JSON if an internet search is required\n",
    "def answer_question(question):\n",
    "    query = f\"\"\"\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    You have access to the google_search tool. Only use the google_search tool if you cannot answer the question from your knowledge. \n",
    "    For example only use the tool if the subject or event is too new.\n",
    "    Skip the preamble.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    converse_api_params = {\n",
    "        \"modelId\": modelId,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": query}]}],\n",
    "        \"toolConfig\": toolConfig,\n",
    "        \"system\": [{ \"text\": \"You are an expert research assistant.\"}],\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": 4096,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = bedrock_runtime_client.converse(**converse_api_params)\n",
    "    \n",
    "    # Check the LLM's response to see if it answered the question or needs to use the internet search tool\n",
    "    google_search = None\n",
    "    for content in response['output']['message']['content']:\n",
    "        if isinstance(content, dict) and 'toolUse' in content:\n",
    "            tool_use = content['toolUse']\n",
    "            if tool_use['name'] == \"google_search\":\n",
    "                google_search = tool_use['input']\n",
    "                break\n",
    "\n",
    "    if google_search:\n",
    "        question = google_search[\"question\"]\n",
    "        # Call the function to get the content from the internet\n",
    "        content = handle_search(question)\n",
    "        if content:\n",
    "            print(\"\\nGoogle search successful\")\n",
    "            response = answer_question_with_content(question, content)\n",
    "            print(f\"\\nFinal answer = {response['output']['message']['content'][-1]['text']}\\n\")\n",
    "        else:\n",
    "            print(\"No content found from Google search\")\n",
    "    else:\n",
    "        print(\"No Google search needed.\")\n",
    "        print(f\"\\nFinal answer is: {response['output']['message']['content'][-1]['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_question(\"Who won the 2019 Masters golf tournament?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Who won the 2023 Masters golf tournament?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"What is the current weather in Seattle, Wa right now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"What is the current time and date in Seattle, WA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"What is the current price on Amazon stock?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Which country won the most gold medals in the 2024 olympics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Which country won the most gold medals in the 2020 olympics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Who is favored to be the next Prime Minister of Canada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"How many Grizzly bears are living in Washington State?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Guardrail\n",
    "Guardrails for Amazon Bedrock have multiple components which include Content Filters, Denied Topics, Word and Phrase Filters, and Sensitive Word (PII & Regex) Filters. For a full list check out the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-create.html) \n",
    "\n",
    "For our research assistant with web access usecase, we want to prevent inappropriate or malicious questions from being sent to the LLM model as well as preventing our model from returning inappropriate responses or exposing any PII data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the boto3 bedrock client to create a Bedrock Guardrail based on the specific controls we want to enforce\n",
    "create_response = bedrock_admin_client.create_guardrail(\n",
    "    name='research-assistant-guardrail',\n",
    "    description='Prevents inappropriate or malicious questions and model answers. Also blocks political topics and anonymizes PII data.',\n",
    "    topicPolicyConfig={\n",
    "        'topicsConfig': [\n",
    "            {\n",
    "                'name': 'Politics',\n",
    "                'definition': 'Preventing the user from asking questions related to politics for any country.',\n",
    "                'examples': [\n",
    "                    'Who is expected to win the next race for Prime Minister of India?',\n",
    "                    'Which politcial party is in power in England?',\n",
    "                    'Which country has had the most impeachments of heads of state?',\n",
    "                    'Who should I vote for in the next election?',\n",
    "                    'Which countries have had the most political scandals this year?'\n",
    "                ],\n",
    "                'type': 'DENY'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    contentPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'SEXUAL',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'VIOLENCE',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'HATE',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'INSULTS',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            },\n",
    "            {\n",
    "                'type': 'MISCONDUCT',\n",
    "                'inputStrength': 'HIGH',\n",
    "                'outputStrength': 'HIGH'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    wordPolicyConfig={\n",
    "        'wordsConfig': [\n",
    "            {'text': 'political party'},\n",
    "            {'text': 'voting for'},\n",
    "            {'text': 'politics'},\n",
    "            {'text': 'voting advice'},\n",
    "            {'text': 'vote for President'},\n",
    "            {'text': 'vote for Prime'},\n",
    "            {'text': 'vote for Chancellor'},\n",
    "            {'text': 'King and Queen'},\n",
    "            {'text': 'Duke and Duchess'},\n",
    "            {'text': 'Chairman of North'},\n",
    "            {'text': 'Supreme Leader'}\n",
    "        ],\n",
    "        'managedWordListsConfig': [\n",
    "            {'type': 'PROFANITY'}\n",
    "        ]\n",
    "    },\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        'piiEntitiesConfig': [\n",
    "            {'type': 'EMAIL', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'PHONE', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'US_SOCIAL_SECURITY_NUMBER', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'US_BANK_ACCOUNT_NUMBER', 'action': 'ANONYMIZE'},\n",
    "            {'type': 'CREDIT_DEBIT_CARD_NUMBER', 'action': 'ANONYMIZE'}\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging=\"\"\"I can provide answers for your research, but I'm not allowed to answer this particular question. Please try a different question. \"\"\",\n",
    "    blockedOutputsMessaging=\"\"\"I'm not allowed to share the answer to this particular question. Please try a different question.\"\"\",\n",
    "    tags=[\n",
    "        {'key': 'purpose', 'value': 'fiduciary-advice-prevention'},\n",
    "        {'key': 'environment', 'value': 'production'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "pprint.pprint(create_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a versioned snapshot of our draft Guardrail \n",
    "version_response = bedrock_admin_client.create_guardrail_version(\n",
    "    guardrailIdentifier=create_response['guardrailId'],\n",
    "    description='Version of research assistant Guardrail'\n",
    ")\n",
    "pprint.pprint(version_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Guardrail config that we can pass into the Converse API call\n",
    "# Use the Guardrail ID and version that we just created above.\n",
    "# Optionally, enable the Guardrail trace so that we can view the effect it has on questions and answers.\n",
    "guardrail_config = {\n",
    "    \"guardrailIdentifier\": version_response['guardrailId'],\n",
    "    \"guardrailVersion\": version_response['version'],\n",
    "    \"trace\": \"enabled\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify the function that answers the question based on google search content to use the Guardrail\n",
    "# Add the Guardrail context to the messages array that we use in the converse API call \n",
    "# Add the Guardrail config to the converse API parameters\n",
    "def answer_question_with_content(question, content):\n",
    "    query = f\"\"\"\n",
    "    Based solely on this content:\n",
    "    <content>\n",
    "    {content}\n",
    "    </content>\n",
    "    Answer this question:\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "    Skip any preamble or references to the tool.\n",
    "    \"\"\"\n",
    "\n",
    "    converse_api_params = {\n",
    "        \"modelId\": modelId,\n",
    "        \"messages\":[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"guardContent\": {\"text\": {\"text\": query}}}]\n",
    "            }\n",
    "        ],\n",
    "        \"system\": [{ \"text\": \"You are an expert research assistant.\" }],\n",
    "        \"inferenceConfig\":{\n",
    "            \"maxTokens\": 4096,\n",
    "            \"temperature\": 0\n",
    "        },\n",
    "        \"guardrailConfig\": guardrail_config,\n",
    "    }\n",
    "\n",
    "    response = bedrock_runtime_client.converse(**converse_api_params)\n",
    "    if response['stopReason'] == \"guardrail_intervened\":\n",
    "            trace = response['trace']\n",
    "            print(\"Guardrail trace:\")\n",
    "            pprint.pprint(trace['guardrail'])\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify the function that answers the question directly or outputs tool use if an internet search is required\n",
    "# Add the Guardrail context to the messages array that we use in the converse API call \n",
    "# Add the Guardrail config to the converse API parameters\n",
    "def answer_question(question):\n",
    "    query = f\"\"\"\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    You have access to the google_search tool. Only use the google_search tool if you cannot answer the question from your knowledge. \n",
    "    For example only use the tool if the subject or event is too new.\n",
    "    Skip the preamble.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    converse_api_params = {\n",
    "        \"modelId\": modelId,\n",
    "        \"messages\":[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"guardContent\": {\"text\": {\"text\": query}}}]\n",
    "            }\n",
    "        ],\n",
    "        \"toolConfig\": toolConfig,\n",
    "        \"system\": [{ \"text\": \"You are an expert research assistant.\" }],\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": 4096,\n",
    "            \"temperature\": 0\n",
    "        },\n",
    "        \"guardrailConfig\": guardrail_config,\n",
    "    }\n",
    "\n",
    "    response = bedrock_runtime_client.converse(**converse_api_params)\n",
    "    if response['stopReason'] == \"guardrail_intervened\":\n",
    "            trace = response['trace']\n",
    "            print(\"Guardrail trace:\")\n",
    "            pprint.pprint(trace['guardrail'])\n",
    "\n",
    "\n",
    "    google_search = None\n",
    "    for content in response['output']['message']['content']:\n",
    "        if isinstance(content, dict) and 'toolUse' in content:\n",
    "            tool_use = content['toolUse']\n",
    "            if tool_use['name'] == \"google_search\":\n",
    "                google_search = tool_use['input']\n",
    "                break\n",
    "\n",
    "    if google_search:\n",
    "        question = google_search[\"question\"]\n",
    "        content = handle_search(question)\n",
    "        if content:\n",
    "            print(\"\\nGoogle search successful\")\n",
    "            response = answer_question_with_content(question, content)\n",
    "            print(f\"\\nFinal answer = {response['output']['message']['content'][-1]['text']}\\n\")\n",
    "        else:\n",
    "            print(\"No content found from Google search\")\n",
    "    else:\n",
    "        print(\"No Google search needed.\")\n",
    "        print(f\"\\nFinal answer is: {response['output']['message']['content'][-1]['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Who won the 2023 Masters golf tournament?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Who is favored to win the next election for Prime Minister of Canada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"What is the email address for AWS Support?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"Where can I purchace brass knuckles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_question(\"How many Grizzly bears are living in Washington State?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
